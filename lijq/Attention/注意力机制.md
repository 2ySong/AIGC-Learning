---
tags:
  - 深度学习
  - 《UnderstandingDeepLearning》
  - 《动手学深度学习》
draft: true
---
> [!attention] 
> - Attention 注意力机制如何适配/处理大文本数据？  
> -  $Q/K/V$ 怎么来的？  
> - 多头注意力怎么实现？
> - self-attention 与 attention 区别？

"The restaurant refused to serve me a ham sandwich, because it only cooks vegetarian food. In the end, they just gave me two slices of bread. Their ambience was just as good as the food and service."

1. 编码输入可能出乎意料的大。（每个英文单词可能由长度 1024 的嵌入向量表示，即便一篇短文其编码输入长度也达到 10 万数量级）
2. [[NLP 自然语言处理|NLP问题]] 的一个定义性特征是每个输入（）的长度不同。网络应该在不同输入位置的单词间共享参数。
3. 语言是模糊的；前者应该“关注”后者（如后出现的代词 it 指代前文的 restaurant），且链接的强度取决于单词本身；有时这些链接需要跨越大段文本。

> [!info]+ 《动手学深度学习》中关于 query/key/value 的说明 
>  
> 自主性的与非自主性的注意力提示解释了人类的注意力的方式，下面来看看如何通过这两种注意力提示，用神经网络来设计注意力机制的框架。  
> 
> 首先，考虑一个相对简单的状况，即只使用非自主性提示。要想将选择偏向于感官输入，则可以简单地使用参数化的全连接层，甚至是非参数化的最大汇聚层或平均汇聚层。因此，**“是否包含自主性提示”将注意力机制与全连接层或汇聚层区别开来**。  
> 
> ![](https://zh-v2.d2l.ai/_images/qkv.svg)
> 在注意力机制中，自主性提示被称为**查询**（query），而非自主性提示（客观存在的咖啡杯和书本）作为**键**（key）与感官输入（sensory inputs）的**值**（value）构成一组 pair 作为输入。而给定任何查询，注意力机制通过**注意力汇聚**（attention pooling）将非自主性提示的 key 引导至感官输入。

> *图片由于来自多个资料，难以确保统一，起到理解效果即可；公式 notation 尽量做到一致（不一致处会作说明）*
## 注意力机制
### 设计思路[^5]
注意力机制做了什么？

注意力机制通过计算**上文语义**来更新词汇向量在向量空间中的位置，从而丰富了**词汇向量的语义含义，最终输出一个包含更加精准语义的新向量**。[^6]

理解词向量之间的相似度？一个简易示例：

 ![../PHOTO/深度学习/注意力机制/Clipboard 2025年12月19日 11.23.png|600](../PHOTO/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/Clipboard%202025%E5%B9%B412%E6%9C%8819%E6%97%A5%2011.23.png)
> Attention 与 self-attention  
> 如果类似上述蓝色例子，查询、键、值**全部来自同一个序列**（或同一层特征），自己跟自己算相似度，即为 self-attention。

上述简易例子中可将上述词向量相关性看做一个注意力分数 $a[\mathbf{x}_m,\mathbf{x}_n]$，每个词**根据注意力分数进行加权求和，得到带注意力分数的 Value**，方便进行下游任务。
$$
\tag{Self-Attention block ouput }\mathbf{sa}_n[\mathbf{x}_1,\ldots,\mathbf{x}_N]=\sum_{m=1}^Na[\mathbf{x}_m,\mathbf{x}_n]\mathbf{v}_m
$$
>  **Softmax 对行做！** 注意力分数矩阵 `QK^T` 的形状是 `n×N`（n 个查询、N 个键）。每一行应对应**同一个查询**与所有 `N` 个键的相似度。  


![|500](https://pic4.zhimg.com/v2-0f40c220deea476da46f616a3154136d_r.jpg)
- 实际操作中通常采用缩放点积，保持矩阵前后的方差不变
$$
Attention(Q,K,V)=Softmax(\frac{QK^\top}{\sqrt{d_k}})V
$$
- Q/K/V 怎么来？
	
	通过神经网络学习得到（其中 $W^Q,W^K,W^V$ 是三个可训练的参数矩阵。）
$$
\begin{aligned}Q&=XW^Q\\K&=XW^K\\V&=XW^V\end{aligned}
$$

> [!check]+ +神经网络的 Attention 图示
> ![../PHOTO/深度学习/注意力机制/img-20251106-1412-51349.png|600](../PHOTO/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/img-20251106-1412-51349.png)
> ![../PHOTO/深度学习/注意力机制/img-20251106-1415-30521.png|600](../PHOTO/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/img-20251106-1415-30521.png)
> ![../PHOTO/深度学习/注意力机制/img-20251106-1416-51106.png|600](../PHOTO/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/img-20251106-1416-51106.png)

> 自注意力模型不是只能用一次，而是可以叠加很多次，全连接网络和自注意力模型交替使用； Transformer 网络架构[^1]中最重要的模块是自注意力模块
### 应用场景
#### 类型 1：输入与输出数量相同
词性标注/语音识别/网络节点特性归类
![../PHOTO/深度学习/注意力机制/img-20251106-1403-23428.png|400](../PHOTO/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/img-20251106-1403-23428.png)
#### 类型 2：输入是一个序列，输出是一个标签
![../PHOTO/深度学习/注意力机制/img-20251106-1403-23427.png|400](../PHOTO/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/img-20251106-1403-23427.png)
#### 类型 3：序列到序列任务
不知道应该输出多少个标签，机器需要自己决定输出多少个标签。如语音识别
![../PHOTO/深度学习/注意力机制/img-20251106-1403-23436.png|400](../PHOTO/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/img-20251106-1403-23436.png)
### 小结
![../PHOTO/深度学习/注意力机制/img-20251219130542339.png|300](../PHOTO/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/img-20251219130542339.png)
- 输入是一组向量，并且输入的向量的数量可以改变，即每次输入模型的向量序列的长度都不一样
- **相比于整体词向量 flatten 后再通过全连接学习，attention 机制在参数量大幅下降的同时也具有对整体序列的理解表示能力**。
![../PHOTO/深度学习/注意力机制/img-20251219130027730.png|600](../PHOTO/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/img-20251219130027730.png)

![[../PHOTO/深度学习/注意力机制/img-20251219131502915.png|500]] [^2]
## 多头注意力
多头自注意力（multi-head self-attention）是自注意力的高级版本。因为相关有很多种不同的形式，也许可以有多个 $q$，不同的 $q$ 负责不同种类的相关性。

现在，对于同样的输入 $X$，定义多组不同的 $W^Q,W^K,W^V$，每组分别计算生成不同的 $Q,K,V$，学习到不同参数。
![../PHOTO/深度学习/注意力机制/img-20251219131520960.png|500](../PHOTO/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/img-20251219131520960.png)
在输出到下一层前，需要将多个输出拼接到一起，乘以矩阵 $W^O$，将维度降低回想要的维度：
![../PHOTO/深度学习/注意力机制/img-20251219131607131.png](../PHOTO/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/img-20251219131607131.png)
![../PHOTO/深度学习/注意力机制/img-20251219130910140.png|300](../PHOTO/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/img-20251219130910140.png)

## 截断自注意力
可以处理向量序列过长的问题。这个范围是人为设定的。在做语音识别的时候，如果要辨识某个位置有什么样的音标，以及这个位置有什么的内容也许没必要让自注意力考虑整个句子，以提高运算的速度

## 与 CNN/RNN/GNN 的对比
【与 CNN 的对比[^3]】

在做卷积神经网络的时候，只考虑感受野范围内的信息；而自注意力会考虑整幅图像的信息，可以看作一种简化版的自注意力

![../PHOTO/深度学习/注意力机制/img-20251106-1403-23473.png|400](../PHOTO/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/img-20251106-1403-23473.png)
![../PHOTO/深度学习/注意力机制/img-20251106-1403-23471 1.png|400](../PHOTO/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/img-20251106-1403-23471%201.png)

【与 RNN 对比[^4]】

- **RNN 无法并行**
- 循环神经网络中的隐向量存储了历史信息，可以看作一种记忆（memory）
- 自注意力的每一个向量都考虑了整个输入序列，而循环神经网络的每一个向量只考虑左边已经输入的向量，而没有考虑右边的向量。但循环神经网络也可以是双向的，如果使用Bi-RNN，则每一个隐状态的输出也可以看作考虑了整个输入序列
- 对于循环神经网络，如果最右边黄色的向量要考虑最左边的输入，则必须把最左边的输入存到记忆里才能不被遗忘，并且直至带到最右边，才能够在最后一个时间点被考虑，但只要自注意力模型输出的查询和键匹配，自注意力模型就可以轻易地从整个序列上非常远的向量中抽取信息

![../PHOTO/深度学习/注意力机制/img-20251106-1403-23474.png|500](../PHOTO/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6/img-20251106-1403-23474.png)

【与 GNN 关系】
- 图中不仅有节点的信息，还有边（edge）的信息，用于表示某些节点间是有关联的
- 关联性不需要机器自动找出来，所以当把自注意力用在图上面的时候，只计算有边相连的节点
- 当把自注意力按照这种限制用在图上面的时候，其实使用的就是一种图神经网络

[^1]: [[1706.03762] Attention Is All You Need](https://arxiv.org/abs/1706.03762)

[^2]: [The Illustrated Transformer – Jay Alammar – Visualizing machine learning one concept at a time.](https://jalammar.github.io/illustrated-transformer/)

[^3]: [[1911.03584] On the Relationship between Self-Attention and Convolutional Layers](https://arxiv.org/abs/1911.03584)

[^4]: [[2006.16236] Transformers are RNNs: Fast Autoregressive Transformers with Linear Attention](https://arxiv.org/abs/2006.16236)

[^5]: [注意力机制到底在做什么，Q/K/V 怎么来的？一文读懂 Attention 注意力机制 - PP 鲁的文章 - 知乎](https://zhuanlan.zhihu.com/p/414084879)

[^6]: [注意力机制到底是什么？ - 远子的回答 - 知乎](https://www.zhihu.com/question/519290359/answer/1889361524008670093)
